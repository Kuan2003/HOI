#!/usr/bin/env python3
"""
Quick sanity checks for VidHOI gaze files produced by
`vidhoi_gt_gaze_extraction.ipynb`.

The script validates that:
1) Every video in the annotation file has a gaze entry.
2) Frame counts between annotations and gaze buffers match.
3) Each annotated human id has a gaze entry (64x64 heatmap or empty list
   when no head is detected).
4) Heatmaps have the expected shape and finite values.
"""

import argparse
import shelve
import sys
from collections import defaultdict
from pathlib import Path

import cv2
import numpy as np


def add_project_root_to_sys_path():
    # project_root = HOI/src/hoi-prediction-gaze-transformer
    project_root = Path(__file__).resolve().parents[1]
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))


add_project_root_to_sys_path()
from common.vidhoi_dataset import VidHOIDataset  # noqa: E402


def parse_args():
    repo_root = Path(__file__).resolve().parents[3]
    default_dataset_root = repo_root / "dataset_vidhoi"
    parser = argparse.ArgumentParser(
        description="Check gaze buffers generated by vidhoi_gt_gaze_extraction.ipynb"
    )
    parser.add_argument(
        "--dataset-root",
        type=Path,
        default=default_dataset_root,
        help="Root of VidHOI dataset (containing images/ and VidHOI_annotation/)",
    )
    parser.add_argument(
        "--split",
        choices=["train", "val"],
        default="train",
        help="Which split to check (controls annotation & gaze file names).",
    )
    parser.add_argument(
        "--gaze-path",
        type=Path,
        default=None,
        help="Override gaze shelve path. Default follows <split>_frame_gazes_gt_bbox",
    )
    parser.add_argument(
        "--head-path",
        type=Path,
        default=None,
        help="Optional head bbox shelve for cross-checking keys.",
    )
    parser.add_argument(
        "--max-videos",
        type=int,
        default=-1,
        help="Limit number of videos to check (for quick spot checks).",
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="Additionally visualize gaze overlaid on RGB frames for one video.",
    )
    parser.add_argument(
        "--vis-video-name",
        type=str,
        default="",
        help="Exact video_name to visualize (e.g. 'p01_cup_stable/video000'). "
        "If empty, use the first video in the dataset.",
    )
    parser.add_argument(
        "--vis-num-frames",
        type=int,
        default=30,
        help="Maximum number of frames to visualize for the selected video.",
    )
    parser.add_argument(
        "--vis-output-dir",
        type=Path,
        default=None,
        help="Directory to save visualization images. Default: <dataset-root>/gaze_vis",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Print per-video issues instead of only summary.",
    )
    return parser.parse_args()


def build_default_paths(dataset_root: Path, split: str):
    ann_file = dataset_root / "VidHOI_annotation" / f"{split}_frame_annots.json"
    gaze_file = dataset_root / "VidHOI_gaze" / f"{split}_frame_gazes_gt_bbox"
    head_file = dataset_root / "VidHOI_gaze" / f"{split}_frame_heads_gt_bbox"
    inout_file = dataset_root / "VidHOI_gaze" / f"{split}_frame_inout_gt_bbox"
    return ann_file, gaze_file, head_file, inout_file


def load_dataset(ann_file: Path, frames_dir: Path):
    if not ann_file.exists():
        raise FileNotFoundError(f"Annotation file not found: {ann_file}")
    if not frames_dir.exists():
        raise FileNotFoundError(f"Frames directory not found: {frames_dir}")
    return VidHOIDataset(
        annotations_file=ann_file,
        frames_dir=frames_dir,
        transform=None,
        min_length=1,
        max_length=999999,
        max_human_num=999999,
        annotation_mode="clip",
    )


def open_shelve(path: Path, required: bool = True):
    """
    Accept a shelve base path (no extension). We treat it as existing if any of
    the companion files (.dat/.dir/.bak or .db) exist.
    """
    if path is None:
        return None

    def _has_any_sidecar(p: Path) -> bool:
        return any((p.with_suffix(suffix)).exists() for suffix in [".dat", ".dir", ".bak", ".db"])

    if not path.exists() and not _has_any_sidecar(path):
        if required:
            raise FileNotFoundError(
                f"Shelve file not found: {path} (looked for {path}.dat/.dir/.bak/.db)"
            )
        return None

    return shelve.open(str(path), flag="r")


def humans_per_frame(labels, bboxes, ids, frame_count, human_label=0):
    """
    Build a list of human-id sets for each frame index.
    """
    frame_map = [set() for _ in range(frame_count)]
    for label, bbox, obj_id in zip(labels, bboxes, ids):
        if label != human_label:
            continue
        im_idx = int(bbox[0])
        if im_idx < 0 or im_idx >= frame_count:
            continue
        frame_map[im_idx].add(int(obj_id))
    return frame_map


def _load_rgb_frames(dataset_root: Path, video_name: str, frame_ids):
    """
    Deprecated helper (kept for backward compatibility if needed).
    Loading is now delegated to VidHOIDataset._load_frames to fully
    respect the original naming convention.
    """
    raise NotImplementedError("Use VidHOIDataset._load_frames instead.")


def visualize_gaze_for_video(
    dataset: VidHOIDataset,
    video_idx: int,
    gaze_db,
    output_dir: Path,
    max_frames: int = 30,
):
    """
    Create images with gaze heatmaps overlaid on RGB frames for one video.
    We aggregate gaze of all humans in a frame by taking the pixel-wise max.
    """
    video_name = dataset.video_name_list[video_idx]
    frame_ids = dataset.frame_ids_list[video_idx]

    if video_name not in gaze_db:
        print(f"[visualize] No gaze entry for video: {video_name}")
        return

    output_dir.mkdir(parents=True, exist_ok=True)
    # use the same loading logic as VidHOIDataset / vidhoi_gt_gaze_extraction
    _, rgb_frames, _ = dataset._load_frames(
        video_name, dataset.frame_ids_list[video_idx], 0, len(frame_ids)
    )
    gaze_frames = gaze_db[video_name]

    num_frames = min(len(rgb_frames), len(gaze_frames), max_frames)
    print(
        f"[visualize] Creating {num_frames} frames for video '{video_name}' "
        f"into '{output_dir}'"
    )

    for idx in range(num_frames):
        img = rgb_frames[idx]
        frame_gaze = gaze_frames[idx]

        if not isinstance(frame_gaze, dict) or len(frame_gaze) == 0:
            combined = None
        else:
            combined = None
            for heatmap in frame_gaze.values():
                if isinstance(heatmap, list) and len(heatmap) == 0:
                    continue
                if not isinstance(heatmap, np.ndarray) or heatmap.size == 0:
                    continue
                # normalize to [0, 1]
                hm = heatmap.astype(np.float32)
                hm_min, hm_max = hm.min(), hm.max()
                if hm_max > hm_min:
                    hm = (hm - hm_min) / (hm_max - hm_min)
                else:
                    hm = np.zeros_like(hm)
                if combined is None:
                    combined = hm
                else:
                    combined = np.maximum(combined, hm)

        vis = img.copy()
        if combined is not None:
            h, w = img.shape[:2]
            hm_resized = cv2.resize(combined, (w, h))
            hm_uint8 = (hm_resized * 255).astype(np.uint8)
            hm_color = cv2.applyColorMap(hm_uint8, cv2.COLORMAP_JET)
            alpha = 0.4
            vis = cv2.addWeighted(img, 1.0, hm_color, alpha, 0)

        out_name = f"{video_name.replace('/', '_')}_{idx:06d}.jpg"
        out_path = output_dir / out_name
        cv2.imwrite(str(out_path), vis)


def check_video(
    video_name,
    frame_ids,
    labels,
    bboxes,
    ids,
    gaze_db,
    head_db=None,
):
    issues = defaultdict(list)
    frame_count = len(frame_ids)
    expected_humans = humans_per_frame(labels, bboxes, ids, frame_count)

    if video_name not in gaze_db:
        issues["missing_gaze_video"].append(video_name)
        return issues

    gaze_frames = gaze_db[video_name]
    if len(gaze_frames) != frame_count:
        issues["frame_count_mismatch"].append(
            f"{video_name}: expected {frame_count}, got {len(gaze_frames)}"
        )
        # continue checking what exists to surface more issues

    head_frames = head_db[video_name] if head_db and video_name in head_db else None

    for idx in range(min(frame_count, len(gaze_frames))):
        frame_gaze = gaze_frames[idx]
        frame_humans = expected_humans[idx]

        if not isinstance(frame_gaze, dict):
            issues["bad_frame_entry"].append(f"{video_name}[{idx}] not a dict")
            continue

        gaze_humans = set(map(int, frame_gaze.keys()))
        missing = frame_humans - gaze_humans
        extra = gaze_humans - frame_humans
        if missing:
            issues["missing_humans"].append(f"{video_name}[{idx}] missing {sorted(missing)}")
        if extra:
            issues["extra_humans"].append(f"{video_name}[{idx}] extra {sorted(extra)}")

        if head_frames:
            head_keys = set(map(int, head_frames[idx].keys()))
            if head_keys != gaze_humans:
                issues["head_gaze_mismatch"].append(
                    f"{video_name}[{idx}] head keys {sorted(head_keys)} != gaze keys {sorted(gaze_humans)}"
                )

        for human_id, heatmap in frame_gaze.items():
            if isinstance(heatmap, list) and len(heatmap) == 0:
                continue  # explicitly marked missing head
            if not isinstance(heatmap, np.ndarray):
                issues["bad_heatmap_type"].append(
                    f"{video_name}[{idx}] human {human_id}: type {type(heatmap)}"
                )
                continue
            if heatmap.shape != (64, 64):
                issues["bad_heatmap_shape"].append(
                    f"{video_name}[{idx}] human {human_id}: shape {heatmap.shape}"
                )
            if not np.isfinite(heatmap).all():
                issues["non_finite"].append(f"{video_name}[{idx}] human {human_id}: non-finite values")

    return issues


def main():
    args = parse_args()
    ann_file, default_gaze_file, default_head_file, _ = build_default_paths(
        args.dataset_root, args.split
    )
    gaze_file = args.gaze_path or default_gaze_file
    head_file = args.head_path or default_head_file

    dataset = load_dataset(ann_file, args.dataset_root / "images")

    gaze_db = open_shelve(gaze_file, required=True)
    head_db = open_shelve(head_file, required=False)

    aggregated = defaultdict(list)
    total_videos = len(dataset.video_name_list)
    to_check = total_videos if args.max_videos < 0 else min(args.max_videos, total_videos)

    for video_idx, video_name in enumerate(dataset.video_name_list[:to_check]):
        labels = dataset.labels_list[video_idx]
        bboxes = dataset.bboxes_list[video_idx]
        ids = dataset.ids_list[video_idx]
        frame_ids = dataset.frame_ids_list[video_idx]

        issues = check_video(video_name, frame_ids, labels, bboxes, ids, gaze_db, head_db)
        for key, msgs in issues.items():
            aggregated[key].extend(msgs)

    print(f"Checked {to_check}/{total_videos} videos from split='{args.split}'.")
    if not aggregated:
        print("No issues found. Gaze buffers look consistent with annotations.")
    else:
        for key, msgs in aggregated.items():
            print(f"- {key}: {len(msgs)} issue(s)")
            if args.verbose:
                for msg in msgs:
                    print(f"    {msg}")

    # Optional visualization for one video
    if args.visualize:
        if args.vis_video_name:
            if args.vis_video_name in dataset.video_name_list:
                video_name = args.vis_video_name
                video_idx = dataset.video_name_list.index(video_name)
            else:
                print(
                    f"[visualize] vis_video_name='{args.vis_video_name}' "
                    "not found in dataset; falling back to first video."
                )
                video_idx = 0
                video_name = dataset.video_name_list[0]
        else:
            video_idx = 0
            video_name = dataset.video_name_list[0]

        vis_dir = (
            args.vis_output_dir
            if args.vis_output_dir is not None
            else args.dataset_root / "gaze_vis"
        )
        try:
            visualize_gaze_for_video(
                dataset,
                video_idx,
                gaze_db,
                vis_dir,
                max_frames=args.vis_num_frames,
            )
        except Exception as e:
            print(f"[visualize] Error while creating visualizations: {e}")

    gaze_db.close()
    if head_db:
        head_db.close()


if __name__ == "__main__":
    main()

