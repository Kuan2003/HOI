{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc0f57d",
   "metadata": {},
   "source": [
    "# Convert VidHOI Custom Dataset to YOLOv5 Format\n",
    "\n",
    "This notebook converts your custom VidHOI dataset annotations to YOLOv5 training format.\n",
    "\n",
    "**Your dataset has 4 object classes:**\n",
    "- person (class 0)\n",
    "- cup (class 1)\n",
    "- plate (class 2)\n",
    "- box (class 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945e45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "241f90e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object classes: ['person', 'cup', 'plate', 'box']\n",
      "Class mapping: {'person': 0, 'cup': 1, 'plate': 2, 'box': 3}\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "dataset_path = Path(\"/home/kuan/Work_Space/Thuc_tap/HOI/dataset_vidhoi\")\n",
    "output_root = Path(\"/home/kuan/Work_Space/Thuc_tap/HOI/yolov5_dataset\")\n",
    "\n",
    "# Your 4 object classes\n",
    "object_classes = ['person', 'cup', 'plate', 'box']\n",
    "name_to_idx = {name: idx for idx, name in enumerate(object_classes)}\n",
    "\n",
    "print(f\"Object classes: {object_classes}\")\n",
    "print(f\"Class mapping: {name_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb692c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations: 5329\n",
      "\n",
      "First annotation example:\n",
      "{\n",
      "  \"video_folder\": \"0484310a-p01_abort_after_touch_video002_p01_abort\",\n",
      "  \"video_id\": \"after\",\n",
      "  \"frame_id\": \"000004\",\n",
      "  \"video_fps\": 10,\n",
      "  \"height\": 720,\n",
      "  \"width\": 1280,\n",
      "  \"middle_frame_timestamp\": 0.4,\n",
      "  \"person_box\": {\n",
      "    \"xmin\": 269,\n",
      "    \"ymin\": 65,\n",
      "    \"xmax\": 595,\n",
      "    \"ymax\": 719\n",
      "  },\n",
      "  \"object_box\": {\n",
      "    \"xmin\": 645,\n",
      "    \"ymin\": 437,\n",
      "    \"xmax\": 725,\n",
      "    \"ymax\": 527\n",
      "  },\n",
      "  \"person_id\": 1,\n",
      "  \"object_id\": 2,\n",
      "  \"object_class\": 1,\n",
      "  \"action_class\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load annotation file\n",
    "train_annotation_path = dataset_path / \"VidHOI_annotation\" / \"train_frame_annots.json\"\n",
    "\n",
    "with train_annotation_path.open(\"r\") as f:\n",
    "    train_annotations = json.load(f)\n",
    "\n",
    "print(f\"Total annotations: {len(train_annotations)}\")\n",
    "print(f\"\\nFirst annotation example:\")\n",
    "print(json.dumps(train_annotations[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9309b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object counts:\n",
      "  person: 0\n",
      "  cup: 2434\n",
      "  plate: 1244\n",
      "  box: 1651\n",
      "\n",
      "Total unique videos: 48\n",
      "Total unique frames: 5099\n"
     ]
    }
   ],
   "source": [
    "# Analyze dataset\n",
    "object_count = defaultdict(int)\n",
    "video_frames = defaultdict(set)\n",
    "\n",
    "for anno in train_annotations:\n",
    "    # Count objects (object_class: 0=person, 1=cup, 2=plate, 3=box)\n",
    "    obj_class_idx = anno['object_class']\n",
    "    if obj_class_idx < len(object_classes):\n",
    "        object_count[object_classes[obj_class_idx]] += 1\n",
    "    \n",
    "    # Track unique frames per video\n",
    "    video_key = f\"{anno['video_folder']}_{anno['video_id']}\"\n",
    "    video_frames[video_key].add(anno['frame_id'])\n",
    "\n",
    "print(\"Object counts:\")\n",
    "for obj_name in object_classes:\n",
    "    print(f\"  {obj_name}: {object_count[obj_name]}\")\n",
    "\n",
    "print(f\"\\nTotal unique videos: {len(video_frames)}\")\n",
    "total_frames = sum(len(frames) for frames in video_frames.values())\n",
    "print(f\"Total unique frames: {total_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_to_yolo(bbox, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert bbox from [xmin, ymin, xmax, ymax] to YOLO format [x_center, y_center, width, height]\n",
    "    All values normalized to [0, 1]\n",
    "    \"\"\"\n",
    "    x_center = ((bbox['xmax'] + bbox['xmin']) / 2) / img_width\n",
    "    y_center = ((bbox['ymax'] + bbox['ymin']) / 2) / img_height\n",
    "    width = (bbox['xmax'] - bbox['xmin']) / img_width\n",
    "    height = (bbox['ymax'] - bbox['ymin']) / img_height\n",
    "    \n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "def generate_yolov5_annotations(annotations, output_path, images_dir):\n",
    "    \"\"\"\n",
    "    Generate YOLOv5 format annotations from VidHOI annotations\n",
    "    \"\"\"\n",
    "    # Group annotations by frame\n",
    "    frame_annotations = defaultdict(list)\n",
    "    \n",
    "    for anno in annotations:\n",
    "        video_folder = anno['video_folder']\n",
    "        video_id = anno['video_id']\n",
    "        frame_id = anno['frame_id']\n",
    "        \n",
    "        # Create unique frame key\n",
    "        frame_key = f\"{video_folder}/{video_id}/{frame_id}\"\n",
    "        frame_annotations[frame_key].append(anno)\n",
    "    \n",
    "    # Create output directories\n",
    "    labels_dir = output_path / \"labels\"\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    image_list = []\n",
    "    missing_images = 0\n",
    "    \n",
    "    for frame_key, annos in tqdm(frame_annotations.items(), desc=\"Converting annotations\"):\n",
    "        parts = frame_key.split('/')\n",
    "        video_folder = parts[0]\n",
    "        video_id = parts[1]\n",
    "        frame_id = parts[2]\n",
    "        \n",
    "        # Create label subdirectories\n",
    "        label_subdir = labels_dir / video_folder / video_id\n",
    "        label_subdir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Label file path\n",
    "       \n",
    "        label_file = label_subdir / f\"{video_id}_{frame_id}.txt\"\n",
    "        # Get image dimensions from first annotation\n",
    "        img_height = annos[0]['height']\n",
    "        img_width = annos[0]['width']\n",
    "        \n",
    "        # Write YOLO format annotations\n",
    "        yolo_lines = []\n",
    "        for anno in annos:\n",
    "            # Person bbox\n",
    "            person_class = 0  # person is always class 0\n",
    "            person_bbox = anno['person_box']\n",
    "            x_c, y_c, w, h = convert_bbox_to_yolo(person_bbox, img_width, img_height)\n",
    "            yolo_lines.append(f\"{person_class} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "            \n",
    "            # Object bbox\n",
    "            object_class = anno['object_class']\n",
    "            object_bbox = anno['object_box']\n",
    "            x_c, y_c, w, h = convert_bbox_to_yolo(object_bbox, img_width, img_height)\n",
    "            yolo_lines.append(f\"{object_class} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "        \n",
    "        # Remove duplicates (same person/object might appear multiple times)\n",
    "        yolo_lines = list(set(yolo_lines))\n",
    "        \n",
    "        # Write label file\n",
    "        with label_file.open('w') as f:\n",
    "            f.writelines(yolo_lines)\n",
    "        \n",
    "        # Image path - FIXED: use video_id prefix in filename\n",
    "        image_path = images_dir / video_folder / video_id / f\"{video_id}_{frame_id}.jpg\"\n",
    "        if image_path.exists():\n",
    "            image_list.append(str(image_path.absolute()) + \"\\n\")\n",
    "        else:\n",
    "            missing_images += 1\n",
    "    \n",
    "    if missing_images > 0:\n",
    "        print(f\"Warning: {missing_images} images not found\")\n",
    "    \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "386fde6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating YOLOv5 annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting annotations: 100%|██████████| 5099/5099 [00:00<00:00, 8890.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 5099 training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate YOLOv5 format annotations\n",
    "images_dir = dataset_path / \"images\"\n",
    "\n",
    "print(\"Generating YOLOv5 annotations...\")\n",
    "image_list = generate_yolov5_annotations(train_annotations, output_root, images_dir)\n",
    "\n",
    "print(f\"\\nGenerated {len(image_list)} training images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "778b20e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying images to YOLOv5 dataset structure...\n",
      "This may take a while but makes the dataset portable for Colab/Kaggle\n",
      "  Copying from: /home/kuan/Work_Space/Thuc_tap/HOI/dataset_vidhoi/images\n",
      "  Copying to: /home/kuan/Work_Space/Thuc_tap/HOI/yolov5_dataset/images\n",
      "✓ Images copied successfully!\n",
      "\n",
      "✓ Images directory ready with 48 folders\n",
      "  Sample: ['9da22909-p01_hold_random_video005_p01', '81dd6fb1-p01_box_stable_video003_p01', 'defa59b1-p01_abort_early_video001_p01']\n"
     ]
    }
   ],
   "source": [
    "# Copy images to YOLOv5 dataset structure (for portability to Colab/Kaggle)\n",
    "# This allows the entire yolov5_dataset folder to be zipped and uploaded anywhere\n",
    "import shutil\n",
    "\n",
    "USE_COPY = True  # Set to True for Colab/Kaggle, False for local symlink\n",
    "\n",
    "images_target = output_root / \"images\"\n",
    "\n",
    "if USE_COPY:\n",
    "    print(\"Copying images to YOLOv5 dataset structure...\")\n",
    "    print(\"This may take a while but makes the dataset portable for Colab/Kaggle\")\n",
    "    \n",
    "    # Remove old directory if exists\n",
    "    if images_target.exists():\n",
    "        print(f\"  Removing old images directory: {images_target}\")\n",
    "        shutil.rmtree(images_target)\n",
    "    \n",
    "    # Copy images maintaining structure\n",
    "    print(f\"  Copying from: {images_dir}\")\n",
    "    print(f\"  Copying to: {images_target}\")\n",
    "    shutil.copytree(images_dir, images_target)\n",
    "    print(f\"✓ Images copied successfully!\")\n",
    "    \n",
    "else:\n",
    "    # Use symlink for local development (faster, saves space)\n",
    "    print(\"Creating symlink (for local use only)...\")\n",
    "    \n",
    "    # Remove old symlink if exists\n",
    "    if images_target.exists() or images_target.is_symlink():\n",
    "        if images_target.is_symlink():\n",
    "            images_target.unlink()\n",
    "        elif images_target.is_dir():\n",
    "            print(f\"Warning: {images_target} is a directory, not removing\")\n",
    "    \n",
    "    # Create symlink\n",
    "    if not images_target.exists():\n",
    "        import os\n",
    "        os.symlink(images_dir, images_target, target_is_directory=True)\n",
    "        print(f\"✓ Created symlink: {images_target} -> {images_dir}\")\n",
    "\n",
    "# Verify structure\n",
    "sample_folders = list(images_target.iterdir())[:3]\n",
    "print(f\"\\n✓ Images directory ready with {len(list(images_target.iterdir()))} folders\")\n",
    "print(f\"  Sample: {[f.name for f in sample_folders]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c8d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking image directory structure...\n",
      "✓ Images directory exists: /home/kuan/Work_Space/Thuc_tap/HOI/dataset_vidhoi/images\n",
      "\n",
      "First 3 subdirectories in images/:\n",
      "  - 9da22909-p01_hold_random_video005_p01\n",
      "    - random\n",
      "      Files: ['random_000031.jpg', 'random_000009.jpg', 'random_000020.jpg']\n",
      "  - 81dd6fb1-p01_box_stable_video003_p01\n",
      "    - stable\n",
      "      Files: ['stable_000005.jpg', 'stable_000128.jpg', 'stable_000105.jpg']\n",
      "  - defa59b1-p01_abort_early_video001_p01\n",
      "    - early\n",
      "      Files: ['early_000108.jpg', 'early_000074.jpg', 'early_000058.jpg']\n",
      "\n",
      "Sample annotation:\n",
      "  video_folder: 0484310a-p01_abort_after_touch_video002_p01_abort\n",
      "  video_id: after\n",
      "  frame_id: 000004\n",
      "\n",
      "Testing different file naming patterns:\n",
      "  000004.jpg                     -> ✗ Not found\n",
      "  after_000004.jpg               -> ✓ EXISTS\n",
      "    Full path: /home/kuan/Work_Space/Thuc_tap/HOI/dataset_vidhoi/images/0484310a-p01_abort_after_touch_video002_p01_abort/after/after_000004.jpg\n",
      "\n",
      "Actual files in after:\n",
      "  - after_000067.jpg\n",
      "  - after_000065.jpg\n",
      "  - after_000039.jpg\n",
      "  - after_000098.jpg\n",
      "  - after_000097.jpg\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check actual image directory structure\n",
    "print(\"Checking image directory structure...\")\n",
    "images_dir = dataset_path / \"images\"\n",
    "\n",
    "# Check if images directory exists\n",
    "if not images_dir.exists():\n",
    "    print(f\"ERROR: Images directory does not exist: {images_dir}\")\n",
    "else:\n",
    "    print(f\"✓ Images directory exists: {images_dir}\")\n",
    "    \n",
    "    # List first few subdirectories\n",
    "    subdirs = list(images_dir.iterdir())[:3]\n",
    "    print(f\"\\nFirst 3 subdirectories in images/:\")\n",
    "    for subdir in subdirs:\n",
    "        print(f\"  - {subdir.name}\")\n",
    "        if subdir.is_dir():\n",
    "            video_dirs = list(subdir.iterdir())[:2]\n",
    "            for vdir in video_dirs:\n",
    "                print(f\"    - {vdir.name}\")\n",
    "                if vdir.is_dir():\n",
    "                    image_files = list(vdir.glob(\"*\"))[:3]\n",
    "                    print(f\"      Files: {[f.name for f in image_files]}\")\n",
    "\n",
    "# Check expected path vs actual path\n",
    "sample_anno = train_annotations[0]\n",
    "print(f\"\\nSample annotation:\")\n",
    "print(f\"  video_folder: {sample_anno['video_folder']}\")\n",
    "print(f\"  video_id: {sample_anno['video_id']}\")\n",
    "print(f\"  frame_id: {sample_anno['frame_id']}\")\n",
    "\n",
    "# Test different naming patterns\n",
    "print(f\"\\nTesting different file naming patterns:\")\n",
    "test_patterns = [\n",
    "    f\"{sample_anno['frame_id']}.jpg\",  # 000004.jpg\n",
    "    f\"{sample_anno['video_id']}_{sample_anno['frame_id']}.jpg\",  # after_000004.jpg\n",
    "    f\"{sample_anno['frame_id'][1:]}.jpg\",  # 00004.jpg (remove leading zero)\n",
    "    f\"{int(sample_anno['frame_id'])}.jpg\",  # 4.jpg (as integer)\n",
    "]\n",
    "\n",
    "for pattern in test_patterns:\n",
    "    test_path = images_dir / sample_anno['video_folder'] / sample_anno['video_id'] / pattern\n",
    "    exists = test_path.exists()\n",
    "    print(f\"  {pattern:30s} -> {'✓ EXISTS' if exists else '✗ Not found'}\")\n",
    "    if exists:\n",
    "        print(f\"    Full path: {test_path}\")\n",
    "        break\n",
    "\n",
    "# If none found, list actual files in that directory\n",
    "video_dir = images_dir / sample_anno['video_folder'] / sample_anno['video_id']\n",
    "if video_dir.exists():\n",
    "    actual_files = list(video_dir.glob(\"*.jpg\"))[:5]\n",
    "    print(f\"\\nActual files in {video_dir.name}:\")\n",
    "    for f in actual_files:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c855dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 4079\n",
      "Validation images: 1020\n",
      "\n",
      "Saved train list to: /home/kuan/Work_Space/Thuc_tap/HOI/yolov5_dataset/train.txt\n",
      "Saved val list to: /home/kuan/Work_Space/Thuc_tap/HOI/yolov5_dataset/val.txt\n",
      "\n",
      "Sample paths:\n",
      "  images/8c585397-p01_abort_early_video004_p01/early/early_000034.jpg\n",
      "  images/fabac5c1-p01_cup_stable_video007_p01/stable/stable_000093.jpg\n"
     ]
    }
   ],
   "source": [
    "# Convert absolute paths to relative paths (relative to output_root)\n",
    "# YOLOv5 expects: ./images/folder/image.jpg with labels at ./labels/folder/image.txt\n",
    "image_list_relative = []\n",
    "for img_path in image_list:\n",
    "    # Convert absolute path to relative path from output_root\n",
    "    # Example: /path/to/dataset_vidhoi/images/folder/video/file.jpg\n",
    "    #       -> ./images/folder/video/file.jpg\n",
    "    abs_path = Path(img_path.strip())\n",
    "    # Get the part after 'images/' directory\n",
    "    rel_parts = abs_path.relative_to(images_dir)\n",
    "    # Create relative path from output_root\n",
    "    rel_path = Path(\"./images\") / rel_parts\n",
    "    image_list_relative.append(str(rel_path) + \"\\n\")\n",
    "\n",
    "# Split into train and validation sets (80/20 split)\n",
    "from random import shuffle, seed\n",
    "\n",
    "seed(42)  # For reproducibility\n",
    "shuffle(image_list_relative)\n",
    "\n",
    "split_idx = int(len(image_list_relative) * 0.8)\n",
    "train_list = image_list_relative[:split_idx]\n",
    "val_list = image_list_relative[split_idx:]\n",
    "\n",
    "print(f\"Training images: {len(train_list)}\")\n",
    "print(f\"Validation images: {len(val_list)}\")\n",
    "\n",
    "# Save image lists\n",
    "train_txt = output_root / \"train.txt\"\n",
    "val_txt = output_root / \"val.txt\"\n",
    "\n",
    "with train_txt.open('w') as f:\n",
    "    f.writelines(train_list)\n",
    "\n",
    "with val_txt.open('w') as f:\n",
    "    f.writelines(val_list)\n",
    "\n",
    "print(f\"\\nSaved train list to: {train_txt}\")\n",
    "print(f\"Saved val list to: {val_txt}\")\n",
    "print(f\"\\nSample paths:\")\n",
    "print(f\"  {train_list[0].strip()}\")\n",
    "print(f\"  {train_list[1].strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c94c5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created YOLOv5 data config: /home/kuan/Work_Space/Thuc_tap/HOI/yolov5_dataset/vidhoi_custom.yaml\n",
      "\n",
      "Config content:\n",
      "# VidHOI Custom Dataset Configuration\n",
      "# Path to dataset root\n",
      "path: /home/kuan/Work_Space/Thuc_tap/HOI/yolov5_dataset\n",
      "\n",
      "# Train/val image lists\n",
      "train: train.txt\n",
      "val: val.txt\n",
      "\n",
      "# Number of classes\n",
      "nc: 4\n",
      "\n",
      "# Class names\n",
      "names: ['person', 'cup', 'plate', 'box']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create YOLOv5 data configuration file\n",
    "data_yaml = output_root / \"vidhoi_custom.yaml\"\n",
    "\n",
    "yaml_content = f\"\"\"# VidHOI Custom Dataset Configuration\n",
    "# Path to dataset root\n",
    "path: {output_root.absolute()}\n",
    "\n",
    "# Train/val image lists\n",
    "train: train.txt\n",
    "val: val.txt\n",
    "\n",
    "# Number of classes\n",
    "nc: {len(object_classes)}\n",
    "\n",
    "# Class names\n",
    "names: {object_classes}\n",
    "\"\"\"\n",
    "\n",
    "with data_yaml.open('w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"Created YOLOv5 data config: {data_yaml}\")\n",
    "print(\"\\nConfig content:\")\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b58d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating compressed archive: /home/kuan/Work_Space/Thuc_tap/HOI/vidhoi_yolov5_dataset.tar.gz\n",
      "This may take several minutes...\n",
      "\n",
      "✓ Archive created successfully!\n",
      "  File: /home/kuan/Work_Space/Thuc_tap/HOI/vidhoi_yolov5_dataset.tar.gz\n",
      "  Size: 1.53 GB\n",
      "\n",
      "You can now upload this file to:\n",
      "  - Google Drive (mount in Colab)\n",
      "  - Kaggle Dataset\n",
      "  - Any cloud storage\n"
     ]
    }
   ],
   "source": [
    "# Create a compressed archive for easy upload to Colab/Kaggle\n",
    "import tarfile\n",
    "\n",
    "archive_name = \"/home/kuan/Work_Space/Thuc_tap/HOI/vidhoi_yolov5_dataset.tar.gz\"\n",
    "\n",
    "print(f\"Creating compressed archive: {archive_name}\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "with tarfile.open(archive_name, \"w:gz\") as tar:\n",
    "    tar.add(output_root, arcname=\"yolov5_dataset\")\n",
    "\n",
    "import os\n",
    "archive_size = os.path.getsize(archive_name) / (1024**3)  # GB\n",
    "print(f\"\\n✓ Archive created successfully!\")\n",
    "print(f\"  File: {archive_name}\")\n",
    "print(f\"  Size: {archive_size:.2f} GB\")\n",
    "print(f\"\\nYou can now upload this file to:\")\n",
    "print(f\"  - Google Drive (mount in Colab)\")\n",
    "print(f\"  - Kaggle Dataset\")\n",
    "print(f\"  - Any cloud storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537df45",
   "metadata": {},
   "source": [
    "## Package for Google Colab / Kaggle\n",
    "\n",
    "The dataset is now ready for Colab/Kaggle with relative paths. You can:\n",
    "\n",
    "### Option 1: Upload entire folder\n",
    "```bash\n",
    "# Zip the dataset\n",
    "cd /home/kuan/Work_Space/Thuc_tap/HOI\n",
    "zip -r yolov5_dataset.zip yolov5_dataset/\n",
    "\n",
    "# Upload to Google Drive or Kaggle Dataset\n",
    "```\n",
    "\n",
    "### Option 2: Create compressed dataset (recommended)\n",
    "Run the next cell to create a compressed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4e3088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample label file: labels/0484310a-p01_abort_after_touch_video002_p01_abort/after/000093.txt\n",
      "\n",
      "Content:\n",
      "1 0.535156 0.669444 0.062500 0.125000\n",
      "0 0.387109 0.544444 0.367969 0.908333\n",
      "\n",
      "\n",
      "Format: class x_center y_center width height\n",
      "Classes: ['person', 'cup', 'plate', 'box']\n"
     ]
    }
   ],
   "source": [
    "# Verify generated annotations\n",
    "import random\n",
    "\n",
    "# Pick a random label file to inspect\n",
    "label_files = list((output_root / \"labels\").rglob(\"*.txt\"))\n",
    "sample_label = random.choice(label_files)\n",
    "\n",
    "print(f\"Sample label file: {sample_label.relative_to(output_root)}\")\n",
    "print(\"\\nContent:\")\n",
    "with sample_label.open('r') as f:\n",
    "    content = f.read()\n",
    "    print(content)\n",
    "\n",
    "print(\"\\nFormat: class x_center y_center width height\")\n",
    "print(f\"Classes: {object_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c9c3a",
   "metadata": {},
   "source": [
    "## Training YOLOv5\n",
    "\n",
    "### Local Training\n",
    "\n",
    "```bash\n",
    "cd modules/object_tracking/yolov5\n",
    "\n",
    "python3 train.py --img 640 --batch 16 --epochs 100 \\\n",
    "    --data /home/kuan/Work_Space/Thuc_tap/HOI/yolov5_dataset/vidhoi_custom.yaml \\\n",
    "    --weights yolov5l.pt \\\n",
    "    --name vidhoi_custom_finetune --cache\n",
    "```\n",
    "\n",
    "### Google Colab Training\n",
    "\n",
    "```python\n",
    "# 1. Upload vidhoi_yolov5_dataset.tar.gz to Google Drive\n",
    "\n",
    "# 2. In Colab notebook:\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 3. Extract dataset\n",
    "!tar -xzf /content/drive/MyDrive/vidhoi_yolov5_dataset.tar.gz -C /content/\n",
    "\n",
    "# 4. Clone YOLOv5\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# 5. Train\n",
    "!python train.py --img 640 --batch 16 --epochs 100 \\\n",
    "    --data /content/yolov5_dataset/vidhoi_custom.yaml \\\n",
    "    --weights yolov5l.pt \\\n",
    "    --name vidhoi_custom --cache\n",
    "```\n",
    "\n",
    "### Kaggle Training\n",
    "\n",
    "```python\n",
    "# 1. Upload vidhoi_yolov5_dataset.tar.gz as Kaggle Dataset\n",
    "\n",
    "# 2. In Kaggle notebook, add the dataset and run:\n",
    "!tar -xzf /kaggle/input/your-dataset-name/vidhoi_yolov5_dataset.tar.gz -C /kaggle/working/\n",
    "\n",
    "# 3. Clone YOLOv5\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# 4. Train\n",
    "!python train.py --img 640 --batch 16 --epochs 100 \\\n",
    "    --data /kaggle/working/yolov5_dataset/vidhoi_custom.yaml \\\n",
    "    --weights yolov5l.pt \\\n",
    "    --name vidhoi_custom --cache\n",
    "```\n",
    "\n",
    "**Notes:**\n",
    "- Relative paths in train.txt/val.txt make the dataset portable\n",
    "- Images are included in the dataset structure\n",
    "- Works on any platform (local, Colab, Kaggle)\n",
    "- Model checkpoints saved in `runs/train/vidhoi_custom/weights/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
